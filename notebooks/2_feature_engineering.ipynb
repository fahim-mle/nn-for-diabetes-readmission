{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering\n",
    "\n",
    "## Objective\n",
    "Encode categorical variables, scale numerical variables, create interaction terms, and select final features for modeling.\n",
    "\n",
    "### Input\n",
    "- `data/processed/1_cleaned_data.csv`\n",
    "\n",
    "### Output\n",
    "- `data/processed/2_featured_data.csv`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and environment set successfully.\n",
      "Project Root: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SETUP CELL: Environment and Imports\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Set project root directory for robust path handling\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\")\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, \"models\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported and environment set successfully.\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Cleaned Data\n",
    "\n",
    "Load the cleaned dataset from the previous notebook and verify its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (101763, 47)\n",
      "\n",
      "First few rows:\n",
      "              race  gender      age  admission_type_id  \\\n",
      "0        Caucasian  Female   [0-10)                  6   \n",
      "1        Caucasian  Female  [10-20)                  1   \n",
      "2  AfricanAmerican  Female  [20-30)                  1   \n",
      "3        Caucasian    Male  [30-40)                  1   \n",
      "4        Caucasian    Male  [40-50)                  1   \n",
      "\n",
      "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "0                        25                    1                 1   \n",
      "1                         1                    7                 3   \n",
      "2                         1                    7                 2   \n",
      "3                         1                    7                 2   \n",
      "4                         1                    7                 1   \n",
      "\n",
      "          medical_specialty  num_lab_procedures  num_procedures  ...  insulin  \\\n",
      "0  Pediatrics-Endocrinology                  41               0  ...       No   \n",
      "1                   Missing                  59               0  ...       Up   \n",
      "2                   Missing                  11               5  ...       No   \n",
      "3                   Missing                  44               1  ...       Up   \n",
      "4                   Missing                  51               0  ...   Steady   \n",
      "\n",
      "   glyburide-metformin  glipizide-metformin  glimepiride-pioglitazone  \\\n",
      "0                   No                   No                        No   \n",
      "1                   No                   No                        No   \n",
      "2                   No                   No                        No   \n",
      "3                   No                   No                        No   \n",
      "4                   No                   No                        No   \n",
      "\n",
      "  metformin-rosiglitazone metformin-pioglitazone change  diabetesMed  \\\n",
      "0                      No                     No     No           No   \n",
      "1                      No                     No     Ch          Yes   \n",
      "2                      No                     No     No          Yes   \n",
      "3                      No                     No     Ch          Yes   \n",
      "4                      No                     No     Ch          Yes   \n",
      "\n",
      "  readmitted readmitted_binary  \n",
      "0         NO                 0  \n",
      "1        >30                 0  \n",
      "2         NO                 0  \n",
      "3         NO                 0  \n",
      "4         NO                 0  \n",
      "\n",
      "[5 rows x 47 columns]\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101763 entries, 0 to 101762\n",
      "Data columns (total 47 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   race                      101763 non-null  object\n",
      " 1   gender                    101763 non-null  object\n",
      " 2   age                       101763 non-null  object\n",
      " 3   admission_type_id         101763 non-null  int64 \n",
      " 4   discharge_disposition_id  101763 non-null  int64 \n",
      " 5   admission_source_id       101763 non-null  int64 \n",
      " 6   time_in_hospital          101763 non-null  int64 \n",
      " 7   medical_specialty         101763 non-null  object\n",
      " 8   num_lab_procedures        101763 non-null  int64 \n",
      " 9   num_procedures            101763 non-null  int64 \n",
      " 10  num_medications           101763 non-null  int64 \n",
      " 11  number_outpatient         101763 non-null  int64 \n",
      " 12  number_emergency          101763 non-null  int64 \n",
      " 13  number_inpatient          101763 non-null  int64 \n",
      " 14  diag_1                    101763 non-null  object\n",
      " 15  diag_2                    101763 non-null  object\n",
      " 16  diag_3                    101763 non-null  object\n",
      " 17  number_diagnoses          101763 non-null  int64 \n",
      " 18  max_glu_serum             5346 non-null    object\n",
      " 19  A1Cresult                 17018 non-null   object\n",
      " 20  metformin                 101763 non-null  object\n",
      " 21  repaglinide               101763 non-null  object\n",
      " 22  nateglinide               101763 non-null  object\n",
      " 23  chlorpropamide            101763 non-null  object\n",
      " 24  glimepiride               101763 non-null  object\n",
      " 25  acetohexamide             101763 non-null  object\n",
      " 26  glipizide                 101763 non-null  object\n",
      " 27  glyburide                 101763 non-null  object\n",
      " 28  tolbutamide               101763 non-null  object\n",
      " 29  pioglitazone              101763 non-null  object\n",
      " 30  rosiglitazone             101763 non-null  object\n",
      " 31  acarbose                  101763 non-null  object\n",
      " 32  miglitol                  101763 non-null  object\n",
      " 33  troglitazone              101763 non-null  object\n",
      " 34  tolazamide                101763 non-null  object\n",
      " 35  examide                   101763 non-null  object\n",
      " 36  citoglipton               101763 non-null  object\n",
      " 37  insulin                   101763 non-null  object\n",
      " 38  glyburide-metformin       101763 non-null  object\n",
      " 39  glipizide-metformin       101763 non-null  object\n",
      " 40  glimepiride-pioglitazone  101763 non-null  object\n",
      " 41  metformin-rosiglitazone   101763 non-null  object\n",
      " 42  metformin-pioglitazone    101763 non-null  object\n",
      " 43  change                    101763 non-null  object\n",
      " 44  diabetesMed               101763 non-null  object\n",
      " 45  readmitted                101763 non-null  object\n",
      " 46  readmitted_binary         101763 non-null  int64 \n",
      "dtypes: int64(12), object(35)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "file_path = os.path.join(PROCESSED_DATA_DIR, '1_cleaned_data.csv')\n",
    "df_clean = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df_clean.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_clean.head())\n",
    "print(\"\\nDataset info:\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Domain-Specific Feature Engineering\n",
    "\n",
    "Create new features based on the research paper's logic about HbA1c measurement and medication changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 medication columns:\n",
      "['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n"
     ]
    }
   ],
   "source": [
    "# Identify the 24 medication columns\n",
    "medication_columns = [col for col in df_clean.columns if col.startswith('metformin') or\n",
    "                     col.startswith('repaglinide') or col.startswith('nateglinide') or\n",
    "                     col.startswith('chlorpropamide') or col.startswith('glimepiride') or\n",
    "                     col.startswith('acetohexamide') or col.startswith('glipizide') or\n",
    "                     col.startswith('glyburide') or col.startswith('tolbutamide') or\n",
    "                     col.startswith('pioglitazone') or col.startswith('rosiglitazone') or\n",
    "                     col.startswith('acarbose') or col.startswith('miglitol') or\n",
    "                     col.startswith('troglitazone') or col.startswith('tolazamide') or\n",
    "                     col.startswith('examide') or col.startswith('citoglipton') or\n",
    "                     col.startswith('insulin') or col.startswith('glyburide-metformin') or\n",
    "                     col.startswith('glipizide-metformin') or col.startswith('glimepiride-pioglitazone') or\n",
    "                     col.startswith('metformin-rosiglitazone') or col.startswith('metformin-pioglitazone')]\n",
    "\n",
    "print(f\"Found {len(medication_columns)} medication columns:\")\n",
    "print(medication_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of change_of_meds feature:\n",
      "change_of_meds\n",
      "0    74060\n",
      "1    27703\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage with medication changes: 27.22%\n"
     ]
    }
   ],
   "source": [
    "# Create the change_of_meds feature\n",
    "# A change is defined as any medication column having 'up' or 'down'\n",
    "med_change_mask = df_clean[medication_columns].isin(['Up', 'Down']).any(axis=1)\n",
    "df_clean['change_of_meds'] = med_change_mask.astype(int)\n",
    "\n",
    "print(\"Distribution of change_of_meds feature:\")\n",
    "print(df_clean['change_of_meds'].value_counts())\n",
    "print(f\"\\nPercentage with medication changes: {df_clean['change_of_meds'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of HbA1c_Change_Group feature:\n",
      "HbA1c_Change_Group\n",
      "No Test            84745\n",
      "High, No Change     7043\n",
      "Normal              4990\n",
      "High, Change        4985\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "HbA1c_Change_Group\n",
      "No Test            83.276829\n",
      "High, No Change     6.920983\n",
      "Normal              4.903550\n",
      "High, Change        4.898637\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the HbA1c_Change_Group feature\n",
    "# This combines HbA1c test results with medication changes\n",
    "conditions = [\n",
    "    df_clean['A1Cresult'].isna(),  # Group 1: No Test\n",
    "    df_clean['A1Cresult'] == 'Norm',  # Group 2: Normal\n",
    "    (df_clean['A1Cresult'].isin(['>7', '>8'])) & (df_clean['change_of_meds'] == 0),  # Group 3: High, No Change\n",
    "    (df_clean['A1Cresult'].isin(['>7', '>8'])) & (df_clean['change_of_meds'] == 1)   # Group 4: High, Change\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'No Test',\n",
    "    'Normal',\n",
    "    'High, No Change',\n",
    "    'High, Change'\n",
    "]\n",
    "\n",
    "df_clean['HbA1c_Change_Group'] = np.select(conditions, choices, default='Unknown')\n",
    "\n",
    "print(\"Distribution of HbA1c_Change_Group feature:\")\n",
    "print(df_clean['HbA1c_Change_Group'].value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(df_clean['HbA1c_Change_Group'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Target and Feature Variables\n",
    "\n",
    "Create the binary target variable and feature matrix for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "readmitted\n",
      "0    90406\n",
      "1    11357\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "readmitted\n",
      "0    88.839755\n",
      "1    11.160245\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class imbalance ratio: 0.126\n"
     ]
    }
   ],
   "source": [
    "# Create the target variable (y)\n",
    "# Convert readmitted to binary: <30 -> 1, >30 or NO -> 0\n",
    "y = (df_clean['readmitted'] == '<30').astype(int)\n",
    "\n",
    "print(\"Target variable distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(y.value_counts(normalize=True) * 100)\n",
    "print(f\"\\nClass imbalance ratio: {y.value_counts()[1] / y.value_counts()[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (101763, 23)\n",
      "\n",
      "Feature columns:\n",
      "['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'diabetesMed', 'change_of_meds', 'HbA1c_Change_Group']\n",
      "\n",
      "First few rows of feature matrix:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "race",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "age",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "admission_type_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "discharge_disposition_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "admission_source_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time_in_hospital",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "medical_specialty",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_lab_procedures",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_procedures",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "num_medications",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number_outpatient",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number_emergency",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number_inpatient",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "diag_1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "diag_2",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "diag_3",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "number_diagnoses",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "max_glu_serum",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "A1Cresult",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "diabetesMed",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "change_of_meds",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HbA1c_Change_Group",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "70a868ea-9e02-4cfa-822b-2c25421795c3",
       "rows": [
        [
         "0",
         "Caucasian",
         "Female",
         "[0-10)",
         "6",
         "25",
         "1",
         "1",
         "Pediatrics-Endocrinology",
         "41",
         "0",
         "1",
         "0",
         "0",
         "0",
         "250.83",
         "0",
         "0",
         "1",
         null,
         null,
         "No",
         "0",
         "No Test"
        ],
        [
         "1",
         "Caucasian",
         "Female",
         "[10-20)",
         "1",
         "1",
         "7",
         "3",
         "Missing",
         "59",
         "0",
         "18",
         "0",
         "0",
         "0",
         "276",
         "250.01",
         "255",
         "9",
         null,
         null,
         "Yes",
         "1",
         "No Test"
        ],
        [
         "2",
         "AfricanAmerican",
         "Female",
         "[20-30)",
         "1",
         "1",
         "7",
         "2",
         "Missing",
         "11",
         "5",
         "13",
         "2",
         "0",
         "1",
         "648",
         "250",
         "V27",
         "6",
         null,
         null,
         "Yes",
         "0",
         "No Test"
        ],
        [
         "3",
         "Caucasian",
         "Male",
         "[30-40)",
         "1",
         "1",
         "7",
         "2",
         "Missing",
         "44",
         "1",
         "16",
         "0",
         "0",
         "0",
         "8",
         "250.43",
         "403",
         "7",
         null,
         null,
         "Yes",
         "1",
         "No Test"
        ],
        [
         "4",
         "Caucasian",
         "Male",
         "[40-50)",
         "1",
         "1",
         "7",
         "1",
         "Missing",
         "51",
         "0",
         "8",
         "0",
         "0",
         "0",
         "197",
         "157",
         "250",
         "5",
         null,
         null,
         "Yes",
         "0",
         "No Test"
        ]
       ],
       "shape": {
        "columns": 23,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>change_of_meds</th>\n",
       "      <th>HbA1c_Change_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pediatrics-Endocrinology</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>250.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>No Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Missing</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>250.01</td>\n",
       "      <td>255</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>No Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Missing</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>648</td>\n",
       "      <td>250</td>\n",
       "      <td>V27</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Missing</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>250.43</td>\n",
       "      <td>403</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>No Test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>157</td>\n",
       "      <td>250</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "0        Caucasian  Female   [0-10)                  6   \n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "0                        25                    1                 1   \n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "\n",
       "          medical_specialty  num_lab_procedures  num_procedures  ...  \\\n",
       "0  Pediatrics-Endocrinology                  41               0  ...   \n",
       "1                   Missing                  59               0  ...   \n",
       "2                   Missing                  11               5  ...   \n",
       "3                   Missing                  44               1  ...   \n",
       "4                   Missing                  51               0  ...   \n",
       "\n",
       "   number_inpatient  diag_1  diag_2  diag_3 number_diagnoses max_glu_serum  \\\n",
       "0                 0  250.83       0       0                1           NaN   \n",
       "1                 0     276  250.01     255                9           NaN   \n",
       "2                 1     648     250     V27                6           NaN   \n",
       "3                 0       8  250.43     403                7           NaN   \n",
       "4                 0     197     157     250                5           NaN   \n",
       "\n",
       "  A1Cresult  diabetesMed change_of_meds HbA1c_Change_Group  \n",
       "0       NaN           No              0            No Test  \n",
       "1       NaN          Yes              1            No Test  \n",
       "2       NaN          Yes              0            No Test  \n",
       "3       NaN          Yes              1            No Test  \n",
       "4       NaN          Yes              0            No Test  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the feature matrix (X)\n",
    "# Drop original readmitted, individual medication columns, and original change column\n",
    "columns_to_drop = ['readmitted', 'readmitted_binary'] + medication_columns + ['change']\n",
    "X = df_clean.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(\"\\nFeature columns:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nFirst few rows of feature matrix:\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identify Numerical and Categorical Features\n",
    "\n",
    "Separate features into numerical and categorical for appropriate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features:\n",
      "['admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'change_of_meds']\n",
      "\n",
      "Count: 12 numerical features\n",
      "\n",
      "Categorical features:\n",
      "['race', 'gender', 'age', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'diabetesMed', 'HbA1c_Change_Group']\n",
      "\n",
      "Count: 11 categorical features\n",
      "\n",
      "Engineered features:\n",
      "change_of_meds: Numerical\n",
      "HbA1c_Change_Group: Categorical\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numerical features:\")\n",
    "print(numerical_features)\n",
    "print(f\"\\nCount: {len(numerical_features)} numerical features\")\n",
    "\n",
    "print(\"\\nCategorical features:\")\n",
    "print(categorical_features)\n",
    "print(f\"\\nCount: {len(categorical_features)} categorical features\")\n",
    "\n",
    "# Verify our engineered features are correctly categorized\n",
    "print(f\"\\nEngineered features:\")\n",
    "print(f\"change_of_meds: {'Numerical' if 'change_of_meds' in numerical_features else 'Categorical'}\")\n",
    "print(f\"HbA1c_Change_Group: {'Numerical' if 'HbA1c_Change_Group' in numerical_features else 'Categorical'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into Training and Testing Sets\n",
    "\n",
    "Split the data using stratification to maintain class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (81410, 23)\n",
      "Testing set shape: (20353, 23)\n",
      "\n",
      "Training target distribution:\n",
      "readmitted\n",
      "0    88.839209\n",
      "1    11.160791\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Testing target distribution:\n",
      "readmitted\n",
      "0    88.84194\n",
      "1    11.15806\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Stratification successful - distributions are similar!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nTesting target distribution:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "print(\"\\nStratification successful - distributions are similar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build Preprocessing Pipeline\n",
    "\n",
    "Create a ColumnTransformer with StandardScaler for numerical features and OneHotEncoder for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor created successfully!\n",
      "Numerical features to scale: 12\n",
      "Categorical features to encode: 11\n",
      "\n",
      "Preprocessor fitted on training data!\n",
      "This prevents data leakage from test set.\n"
     ]
    }
   ],
   "source": [
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified\n",
    ")\n",
    "\n",
    "print(\"Preprocessor created successfully!\")\n",
    "print(f\"Numerical features to scale: {len(numerical_features)}\")\n",
    "print(f\"Categorical features to encode: {len(categorical_features)}\")\n",
    "\n",
    "# Fit the preprocessor on training data only\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "print(\"\\nPreprocessor fitted on training data!\")\n",
    "print(\"This prevents data leakage from test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Transform the Data\n",
    "\n",
    "Apply the fitted preprocessor to transform both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation completed!\n",
      "Original training shape: (81410, 23)\n",
      "Transformed training shape: (81410, 2290)\n",
      "Original testing shape: (20353, 23)\n",
      "Transformed testing shape: (20353, 2290)\n",
      "\n",
      "Feature expansion due to one-hot encoding: 2267 new features\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "Sample values from transformed training data (first 5 features of first sample):\n",
      "[ 0.67700876  2.70926497 -1.17301699  1.20916585 -1.27570736]\n"
     ]
    }
   ],
   "source": [
    "# Transform the training and testing data\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Data transformation completed!\")\n",
    "print(f\"Original training shape: {X_train.shape}\")\n",
    "print(f\"Transformed training shape: {X_train_transformed.shape}\")\n",
    "print(f\"Original testing shape: {X_test.shape}\")\n",
    "print(f\"Transformed testing shape: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"\\nFeature expansion due to one-hot encoding: {X_train_transformed.shape[1] - X_train.shape[1]} new features\")\n",
    "print(f\"Data type: {type(X_train_transformed)}\")\n",
    "print(f\"Sample values from transformed training data (first 5 features of first sample):\")\n",
    "print(X_train_transformed[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7b: Address Class Imbalance with SMOTE\n",
    "\n",
    "**Critical:** The severe class imbalance (88.8% vs 11.2%) will cause poor recall for readmissions.\n",
    "\n",
    "We use **SMOTE (Synthetic Minority Over-sampling Technique)** to balance the training data:\n",
    "- Creates synthetic samples for the minority class (readmissions)\n",
    "- **Only applied to training data** - never to test data\n",
    "- Prevents the model from being biased toward predicting \"no readmission\"\n",
    "\n",
    "This is essential for healthcare applications where detecting readmissions (minority class) is critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution BEFORE SMOTE:\n",
      "======================================================================\n",
      "Training set:\n",
      "  Class 0 (No Readmission): 72324 (88.84%)\n",
      "  Class 1 (Readmission):    9086 (11.16%)\n",
      "  Imbalance Ratio: 0.126\n",
      "======================================================================\n",
      "Applying SMOTE to balance training data...\n",
      "Class Distribution AFTER SMOTE:\n",
      "======================================================================\n",
      "Training set:\n",
      "  Class 0 (No Readmission): 72324 (50.00%)\n",
      "  Class 1 (Readmission):    72324 (50.00%)\n",
      "  Imbalance Ratio: 1.000\n",
      "======================================================================\n",
      "Original training samples: 81410\n",
      "Resampled training samples: 144648\n",
      "Synthetic samples created: 63238\n",
      "⚠ IMPORTANT: Test set remains unchanged to provide unbiased evaluation!\n",
      "Test set shape: (20353, 2290)\n",
      "Test set class distribution:\n",
      "  Class 0: 18082 (88.84%)\n",
      "  Class 1: 2271 (11.16%)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Check class distribution before SMOTE\n",
    "print(\"Class Distribution BEFORE SMOTE:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training set:\")\n",
    "print(f\"  Class 0 (No Readmission): {(y_train == 0).sum()} ({(y_train == 0).sum() / len(y_train) * 100:.2f}%)\")\n",
    "print(f\"  Class 1 (Readmission):    {(y_train == 1).sum()} ({(y_train == 1).sum() / len(y_train) * 100:.2f}%)\")\n",
    "print(f\"  Imbalance Ratio: {(y_train == 1).sum() / (y_train == 0).sum():.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Apply SMOTE to training data only\n",
    "print(\"Applying SMOTE to balance training data...\")\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_transformed, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"Class Distribution AFTER SMOTE:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training set:\")\n",
    "print(f\"  Class 0 (No Readmission): {(y_train_resampled == 0).sum()} ({(y_train_resampled == 0).sum() / len(y_train_resampled) * 100:.2f}%)\")\n",
    "print(f\"  Class 1 (Readmission):    {(y_train_resampled == 1).sum()} ({(y_train_resampled == 1).sum() / len(y_train_resampled) * 100:.2f}%)\")\n",
    "print(f\"  Imbalance Ratio: {(y_train_resampled == 1).sum() / (y_train_resampled == 0).sum():.3f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"Original training samples: {X_train_transformed.shape[0]}\")\n",
    "print(f\"Resampled training samples: {X_train_resampled.shape[0]}\")\n",
    "print(f\"Synthetic samples created: {X_train_resampled.shape[0] - X_train_transformed.shape[0]}\")\n",
    "\n",
    "print(\"⚠ IMPORTANT: Test set remains unchanged to provide unbiased evaluation!\")\n",
    "print(f\"Test set shape: {X_test_transformed.shape}\")\n",
    "print(f\"Test set class distribution:\")\n",
    "print(f\"  Class 0: {(y_test == 0).sum()} ({(y_test == 0).sum() / len(y_test) * 100:.2f}%)\")\n",
    "print(f\"  Class 1: {(y_test == 1).sum()} ({(y_test == 1).sum() / len(y_test) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Preprocessor and Final Data\n",
    "\n",
    "Save the fitted preprocessor and transformed data for use in the modeling notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor saved to: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main/models/preprocessor.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data saved to: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main/data/processed/3_final_data_resampled.npz\n",
      "  - Training data: RESAMPLED (balanced classes)\n",
      "  - Test data: ORIGINAL (real-world distribution)\n",
      "Featured data saved to: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main/data/processed/2_featured_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessor\n",
    "preprocessor_path = os.path.join(MODELS_DIR, \"preprocessor.joblib\")\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"Preprocessor saved to: {preprocessor_path}\")\n",
    "\n",
    "# Save the RESAMPLED training data with original test data\n",
    "final_data_path = os.path.join(PROCESSED_DATA_DIR, \"3_final_data_resampled.npz\")\n",
    "np.savez_compressed(\n",
    "    final_data_path,\n",
    "    X_train=X_train_resampled,  # Using resampled training data\n",
    "    X_test=X_test_transformed,   # Original test data (no resampling)\n",
    "    y_train=y_train_resampled,   # Resampled training labels\n",
    "    y_test=y_test.values         # Original test labels\n",
    ")\n",
    "print(f\"Final data saved to: {final_data_path}\")\n",
    "print(f\"  - Training data: RESAMPLED (balanced classes)\")\n",
    "print(f\"  - Test data: ORIGINAL (real-world distribution)\")\n",
    "\n",
    "# Also save the feature engineering results as CSV for reference\n",
    "featured_data_path = os.path.join(PROCESSED_DATA_DIR, \"2_featured_data.csv\")\n",
    "df_featured = X.copy()\n",
    "df_featured[\"readmitted_binary\"] = y\n",
    "df_featured.to_csv(featured_data_path, index=False)\n",
    "print(f\"Featured data saved to: {featured_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Feature engineering completed successfully! Key accomplishments:\n",
    "\n",
    "1. **Domain-Specific Features Created:**\n",
    "   - `change_of_meds`: Binary feature indicating medication changes\n",
    "   - `HbA1c_Change_Group`: 4-category feature combining HbA1c results with medication changes\n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "   - Target variable converted to binary (<30 days = 1, others = 0)\n",
    "   - 24 individual medication columns removed (information captured in engineered features)\n",
    "   - Features separated into numerical and categorical for appropriate processing\n",
    "\n",
    "3. **Pipeline Construction:**\n",
    "   - StandardScaler applied to numerical features\n",
    "   - OneHotEncoder applied to categorical features\n",
    "   - Proper train/test split with stratification\n",
    "   - Preprocessor fitted only on training data to prevent leakage\n",
    "\n",
    "4. **Class Imbalance Handling (CRITICAL):**\n",
    "   - Applied SMOTE to training data to balance classes (88.8% → 50/50)\n",
    "   - Test data kept at original distribution for unbiased evaluation\n",
    "   - This prevents poor recall for the minority class (readmissions)\n",
    "\n",
    "5. **Outputs Saved:**\n",
    "   - `preprocessor.joblib`: Fitted preprocessor for reuse\n",
    "   - `3_final_data.npz`: **Resampled** training data + original test data\n",
    "   - `2_featured_data.csv`: Reference dataset with engineered features\n",
    "\n",
    "The data is now ready for neural network modeling in Notebook 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
