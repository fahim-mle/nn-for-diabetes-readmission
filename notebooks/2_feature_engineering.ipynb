{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering\n",
    "\n",
    "## Objective\n",
    "Encode categorical variables, scale numerical variables, create interaction terms, and select final features for modeling.\n",
    "\n",
    "### Input\n",
    "- `data/processed/1_cleaned_data.csv`\n",
    "\n",
    "### Output\n",
    "- `data/processed/2_featured_data.csv`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and environment set successfully.\n",
      "Project Root: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SETUP CELL: Environment and Imports\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "# Set project root directory for robust path handling\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, 'data')\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported and environment set successfully.\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Cleaned Data\n",
    "\n",
    "Load the cleaned dataset from the previous notebook and verify its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (101763, 47)\n",
      "\n",
      "First few rows:\n",
      "              race  gender      age  admission_type_id  \\\n",
      "0        Caucasian  Female   [0-10)                  6   \n",
      "1        Caucasian  Female  [10-20)                  1   \n",
      "2  AfricanAmerican  Female  [20-30)                  1   \n",
      "3        Caucasian    Male  [30-40)                  1   \n",
      "4        Caucasian    Male  [40-50)                  1   \n",
      "\n",
      "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "0                        25                    1                 1   \n",
      "1                         1                    7                 3   \n",
      "2                         1                    7                 2   \n",
      "3                         1                    7                 2   \n",
      "4                         1                    7                 1   \n",
      "\n",
      "          medical_specialty  num_lab_procedures  num_procedures  ...  insulin  \\\n",
      "0  Pediatrics-Endocrinology                  41               0  ...       No   \n",
      "1                   Missing                  59               0  ...       Up   \n",
      "2                   Missing                  11               5  ...       No   \n",
      "3                   Missing                  44               1  ...       Up   \n",
      "4                   Missing                  51               0  ...   Steady   \n",
      "\n",
      "   glyburide-metformin  glipizide-metformin  glimepiride-pioglitazone  \\\n",
      "0                   No                   No                        No   \n",
      "1                   No                   No                        No   \n",
      "2                   No                   No                        No   \n",
      "3                   No                   No                        No   \n",
      "4                   No                   No                        No   \n",
      "\n",
      "  metformin-rosiglitazone metformin-pioglitazone change  diabetesMed  \\\n",
      "0                      No                     No     No           No   \n",
      "1                      No                     No     Ch          Yes   \n",
      "2                      No                     No     No          Yes   \n",
      "3                      No                     No     Ch          Yes   \n",
      "4                      No                     No     Ch          Yes   \n",
      "\n",
      "  readmitted readmitted_binary  \n",
      "0         NO                 0  \n",
      "1        >30                 0  \n",
      "2         NO                 0  \n",
      "3         NO                 0  \n",
      "4         NO                 0  \n",
      "\n",
      "[5 rows x 47 columns]\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101763 entries, 0 to 101762\n",
      "Data columns (total 47 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   race                      101763 non-null  object\n",
      " 1   gender                    101763 non-null  object\n",
      " 2   age                       101763 non-null  object\n",
      " 3   admission_type_id         101763 non-null  int64 \n",
      " 4   discharge_disposition_id  101763 non-null  int64 \n",
      " 5   admission_source_id       101763 non-null  int64 \n",
      " 6   time_in_hospital          101763 non-null  int64 \n",
      " 7   medical_specialty         101763 non-null  object\n",
      " 8   num_lab_procedures        101763 non-null  int64 \n",
      " 9   num_procedures            101763 non-null  int64 \n",
      " 10  num_medications           101763 non-null  int64 \n",
      " 11  number_outpatient         101763 non-null  int64 \n",
      " 12  number_emergency          101763 non-null  int64 \n",
      " 13  number_inpatient          101763 non-null  int64 \n",
      " 14  diag_1                    101763 non-null  object\n",
      " 15  diag_2                    101763 non-null  object\n",
      " 16  diag_3                    101763 non-null  object\n",
      " 17  number_diagnoses          101763 non-null  int64 \n",
      " 18  max_glu_serum             5346 non-null    object\n",
      " 19  A1Cresult                 17018 non-null   object\n",
      " 20  metformin                 101763 non-null  object\n",
      " 21  repaglinide               101763 non-null  object\n",
      " 22  nateglinide               101763 non-null  object\n",
      " 23  chlorpropamide            101763 non-null  object\n",
      " 24  glimepiride               101763 non-null  object\n",
      " 25  acetohexamide             101763 non-null  object\n",
      " 26  glipizide                 101763 non-null  object\n",
      " 27  glyburide                 101763 non-null  object\n",
      " 28  tolbutamide               101763 non-null  object\n",
      " 29  pioglitazone              101763 non-null  object\n",
      " 30  rosiglitazone             101763 non-null  object\n",
      " 31  acarbose                  101763 non-null  object\n",
      " 32  miglitol                  101763 non-null  object\n",
      " 33  troglitazone              101763 non-null  object\n",
      " 34  tolazamide                101763 non-null  object\n",
      " 35  examide                   101763 non-null  object\n",
      " 36  citoglipton               101763 non-null  object\n",
      " 37  insulin                   101763 non-null  object\n",
      " 38  glyburide-metformin       101763 non-null  object\n",
      " 39  glipizide-metformin       101763 non-null  object\n",
      " 40  glimepiride-pioglitazone  101763 non-null  object\n",
      " 41  metformin-rosiglitazone   101763 non-null  object\n",
      " 42  metformin-pioglitazone    101763 non-null  object\n",
      " 43  change                    101763 non-null  object\n",
      " 44  diabetesMed               101763 non-null  object\n",
      " 45  readmitted                101763 non-null  object\n",
      " 46  readmitted_binary         101763 non-null  int64 \n",
      "dtypes: int64(12), object(35)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned data\n",
    "file_path = os.path.join(PROCESSED_DATA_DIR, '1_cleaned_data.csv')\n",
    "df_clean = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df_clean.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_clean.head())\n",
    "print(\"\\nDataset info:\")\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Domain-Specific Feature Engineering\n",
    "\n",
    "Create new features based on the research paper's logic about HbA1c measurement and medication changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 medication columns:\n",
      "['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n"
     ]
    }
   ],
   "source": [
    "# Identify the 24 medication columns\n",
    "medication_columns = [col for col in df_clean.columns if col.startswith('metformin') or\n",
    "                     col.startswith('repaglinide') or col.startswith('nateglinide') or\n",
    "                     col.startswith('chlorpropamide') or col.startswith('glimepiride') or\n",
    "                     col.startswith('acetohexamide') or col.startswith('glipizide') or\n",
    "                     col.startswith('glyburide') or col.startswith('tolbutamide') or\n",
    "                     col.startswith('pioglitazone') or col.startswith('rosiglitazone') or\n",
    "                     col.startswith('acarbose') or col.startswith('miglitol') or\n",
    "                     col.startswith('troglitazone') or col.startswith('tolazamide') or\n",
    "                     col.startswith('examide') or col.startswith('citoglipton') or\n",
    "                     col.startswith('insulin') or col.startswith('glyburide-metformin') or\n",
    "                     col.startswith('glipizide-metformin') or col.startswith('glimepiride-pioglitazone') or\n",
    "                     col.startswith('metformin-rosiglitazone') or col.startswith('metformin-pioglitazone')]\n",
    "\n",
    "print(f\"Found {len(medication_columns)} medication columns:\")\n",
    "print(medication_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of change_of_meds feature:\n",
      "change_of_meds\n",
      "0    101763\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage with medication changes: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Create the change_of_meds feature\n",
    "# A change is defined as any medication column having 'up' or 'down'\n",
    "med_change_mask = df_clean[medication_columns].isin(['up', 'down']).any(axis=1)\n",
    "df_clean['change_of_meds'] = med_change_mask.astype(int)\n",
    "\n",
    "print(\"Distribution of change_of_meds feature:\")\n",
    "print(df_clean['change_of_meds'].value_counts())\n",
    "print(f\"\\nPercentage with medication changes: {df_clean['change_of_meds'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of HbA1c_Change_Group feature:\n",
      "HbA1c_Change_Group\n",
      "Unknown            84745\n",
      "High, No Change    12028\n",
      "Normal              4990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "HbA1c_Change_Group\n",
      "Unknown            83.276829\n",
      "High, No Change    11.819620\n",
      "Normal              4.903550\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create the HbA1c_Change_Group feature\n",
    "# This combines HbA1c test results with medication changes\n",
    "conditions = [\n",
    "    df_clean['A1Cresult'] == 'None',  # Group 1: No Test\n",
    "    df_clean['A1Cresult'] == 'Norm',  # Group 2: Normal\n",
    "    (df_clean['A1Cresult'].isin(['>7', '>8'])) & (df_clean['change_of_meds'] == 0),  # Group 3: High, No Change\n",
    "    (df_clean['A1Cresult'].isin(['>7', '>8'])) & (df_clean['change_of_meds'] == 1)   # Group 4: High, Change\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'No Test',\n",
    "    'Normal',\n",
    "    'High, No Change',\n",
    "    'High, Change'\n",
    "]\n",
    "\n",
    "df_clean['HbA1c_Change_Group'] = np.select(conditions, choices, default='Unknown')\n",
    "\n",
    "print(\"Distribution of HbA1c_Change_Group feature:\")\n",
    "print(df_clean['HbA1c_Change_Group'].value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(df_clean['HbA1c_Change_Group'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Target and Feature Variables\n",
    "\n",
    "Create the binary target variable and feature matrix for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable distribution:\n",
      "readmitted\n",
      "0    90406\n",
      "1    11357\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentage distribution:\n",
      "readmitted\n",
      "0    88.839755\n",
      "1    11.160245\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class imbalance ratio: 0.126\n"
     ]
    }
   ],
   "source": [
    "# Create the target variable (y)\n",
    "# Convert readmitted to binary: <30 -> 1, >30 or NO -> 0\n",
    "y = (df_clean['readmitted'] == '<30').astype(int)\n",
    "\n",
    "print(\"Target variable distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(y.value_counts(normalize=True) * 100)\n",
    "print(f\"\\nClass imbalance ratio: {y.value_counts()[1] / y.value_counts()[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (101763, 24)\n",
      "\n",
      "Feature columns:\n",
      "['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'diabetesMed', 'readmitted_binary', 'change_of_meds', 'HbA1c_Change_Group']\n",
      "\n",
      "First few rows of feature matrix:\n",
      "              race  gender      age  admission_type_id  \\\n",
      "0        Caucasian  Female   [0-10)                  6   \n",
      "1        Caucasian  Female  [10-20)                  1   \n",
      "2  AfricanAmerican  Female  [20-30)                  1   \n",
      "3        Caucasian    Male  [30-40)                  1   \n",
      "4        Caucasian    Male  [40-50)                  1   \n",
      "\n",
      "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
      "0                        25                    1                 1   \n",
      "1                         1                    7                 3   \n",
      "2                         1                    7                 2   \n",
      "3                         1                    7                 2   \n",
      "4                         1                    7                 1   \n",
      "\n",
      "          medical_specialty  num_lab_procedures  num_procedures  ...  diag_1  \\\n",
      "0  Pediatrics-Endocrinology                  41               0  ...  250.83   \n",
      "1                   Missing                  59               0  ...     276   \n",
      "2                   Missing                  11               5  ...     648   \n",
      "3                   Missing                  44               1  ...       8   \n",
      "4                   Missing                  51               0  ...     197   \n",
      "\n",
      "   diag_2  diag_3  number_diagnoses max_glu_serum A1Cresult diabetesMed  \\\n",
      "0       0       0                 1           NaN       NaN          No   \n",
      "1  250.01     255                 9           NaN       NaN         Yes   \n",
      "2     250     V27                 6           NaN       NaN         Yes   \n",
      "3  250.43     403                 7           NaN       NaN         Yes   \n",
      "4     157     250                 5           NaN       NaN         Yes   \n",
      "\n",
      "   readmitted_binary change_of_meds HbA1c_Change_Group  \n",
      "0                  0              0            Unknown  \n",
      "1                  0              0            Unknown  \n",
      "2                  0              0            Unknown  \n",
      "3                  0              0            Unknown  \n",
      "4                  0              0            Unknown  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the feature matrix (X)\n",
    "# Drop original readmitted, individual medication columns, and original change column\n",
    "columns_to_drop = ['readmitted'] + medication_columns + ['change']\n",
    "X = df_clean.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(\"\\nFeature columns:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nFirst few rows of feature matrix:\")\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identify Numerical and Categorical Features\n",
    "\n",
    "Separate features into numerical and categorical for appropriate preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features:\n",
      "['admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'readmitted_binary', 'change_of_meds']\n",
      "\n",
      "Count: 13 numerical features\n",
      "\n",
      "Categorical features:\n",
      "['race', 'gender', 'age', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'diabetesMed', 'HbA1c_Change_Group']\n",
      "\n",
      "Count: 11 categorical features\n",
      "\n",
      "Engineered features:\n",
      "change_of_meds: Numerical\n",
      "HbA1c_Change_Group: Categorical\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numerical features:\")\n",
    "print(numerical_features)\n",
    "print(f\"\\nCount: {len(numerical_features)} numerical features\")\n",
    "\n",
    "print(\"\\nCategorical features:\")\n",
    "print(categorical_features)\n",
    "print(f\"\\nCount: {len(categorical_features)} categorical features\")\n",
    "\n",
    "# Verify our engineered features are correctly categorized\n",
    "print(f\"\\nEngineered features:\")\n",
    "print(f\"change_of_meds: {'Numerical' if 'change_of_meds' in numerical_features else 'Categorical'}\")\n",
    "print(f\"HbA1c_Change_Group: {'Numerical' if 'HbA1c_Change_Group' in numerical_features else 'Categorical'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split Data into Training and Testing Sets\n",
    "\n",
    "Split the data using stratification to maintain class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (81410, 24)\n",
      "Testing set shape: (20353, 24)\n",
      "\n",
      "Training target distribution:\n",
      "readmitted\n",
      "0    88.839209\n",
      "1    11.160791\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Testing target distribution:\n",
      "readmitted\n",
      "0    88.84194\n",
      "1    11.15806\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Stratification successful - distributions are similar!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nTesting target distribution:\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n",
    "print(\"\\nStratification successful - distributions are similar!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Build Preprocessing Pipeline\n",
    "\n",
    "Create a ColumnTransformer with StandardScaler for numerical features and OneHotEncoder for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor created successfully!\n",
      "Numerical features to scale: 13\n",
      "Categorical features to encode: 11\n",
      "\n",
      "Preprocessor fitted on training data!\n",
      "This prevents data leakage from test set.\n"
     ]
    }
   ],
   "source": [
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any columns not specified\n",
    ")\n",
    "\n",
    "print(\"Preprocessor created successfully!\")\n",
    "print(f\"Numerical features to scale: {len(numerical_features)}\")\n",
    "print(f\"Categorical features to encode: {len(categorical_features)}\")\n",
    "\n",
    "# Fit the preprocessor on training data only\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "print(\"\\nPreprocessor fitted on training data!\")\n",
    "print(\"This prevents data leakage from test set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Transform the Data\n",
    "\n",
    "Apply the fitted preprocessor to transform both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformation completed!\n",
      "Original training shape: (81410, 24)\n",
      "Transformed training shape: (81410, 2290)\n",
      "Original testing shape: (20353, 24)\n",
      "Transformed testing shape: (20353, 2290)\n",
      "\n",
      "Feature expansion due to one-hot encoding: 2266 new features\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "Sample values from transformed training data (first 5 features of first sample):\n",
      "[ 0.67700876  2.70926497 -1.17301699  1.20916585 -1.27570736]\n"
     ]
    }
   ],
   "source": [
    "# Transform the training and testing data\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Data transformation completed!\")\n",
    "print(f\"Original training shape: {X_train.shape}\")\n",
    "print(f\"Transformed training shape: {X_train_transformed.shape}\")\n",
    "print(f\"Original testing shape: {X_test.shape}\")\n",
    "print(f\"Transformed testing shape: {X_test_transformed.shape}\")\n",
    "\n",
    "print(f\"\\nFeature expansion due to one-hot encoding: {X_train_transformed.shape[1] - X_train.shape[1]} new features\")\n",
    "print(f\"Data type: {type(X_train_transformed)}\")\n",
    "print(f\"Sample values from transformed training data (first 5 features of first sample):\")\n",
    "print(X_train_transformed[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Preprocessor and Final Data\n",
    "\n",
    "Save the fitted preprocessor and transformed data for use in the modeling notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor saved to: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main/models/preprocessor.joblib\n",
      "Final data saved to: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main/data/processed/3_final_data.npz\n",
      "Featured data saved to: /home/ghost/workspace/university/machine_learning_and_computer_vision/assessment_main/data/processed/2_featured_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the preprocessor\n",
    "preprocessor_path = os.path.join(MODELS_DIR, 'preprocessor.joblib')\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"Preprocessor saved to: {preprocessor_path}\")\n",
    "\n",
    "# Save the transformed data and targets\n",
    "final_data_path = os.path.join(PROCESSED_DATA_DIR, '3_final_data.npz')\n",
    "np.savez_compressed(\n",
    "    final_data_path,\n",
    "    X_train_transformed=X_train_transformed,\n",
    "    X_test_transformed=X_test_transformed,\n",
    "    y_train=y_train.values,\n",
    "    y_test=y_test.values\n",
    ")\n",
    "print(f\"Final data saved to: {final_data_path}\")\n",
    "\n",
    "# Also save the feature engineering results as CSV for reference\n",
    "featured_data_path = os.path.join(PROCESSED_DATA_DIR, '2_featured_data.csv')\n",
    "df_featured = X.copy()\n",
    "df_featured['readmitted_binary'] = y\n",
    "df_featured.to_csv(featured_data_path, index=False)\n",
    "print(f\"Featured data saved to: {featured_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Feature engineering completed successfully! Key accomplishments:\n",
    "\n",
    "1. **Domain-Specific Features Created:**\n",
    "   - `change_of_meds`: Binary feature indicating medication changes\n",
    "   - `HbA1c_Change_Group`: 4-category feature combining HbA1c results with medication changes\n",
    "\n",
    "2. **Data Preprocessing:**\n",
    "   - Target variable converted to binary (<30 days = 1, others = 0)\n",
    "   - 24 individual medication columns removed (information captured in engineered features)\n",
    "   - Features separated into numerical and categorical for appropriate processing\n",
    "\n",
    "3. **Pipeline Construction:**\n",
    "   - StandardScaler applied to numerical features\n",
    "   - OneHotEncoder applied to categorical features\n",
    "   - Proper train/test split with stratification\n",
    "   - Preprocessor fitted only on training data to prevent leakage\n",
    "\n",
    "4. **Outputs Saved:**\n",
    "   - `preprocessor.joblib`: Fitted preprocessor for reuse\n",
    "   - `3_final_data.npz`: Transformed training and testing data\n",
    "   - `2_featured_data.csv`: Reference dataset with engineered features\n",
    "\n",
    "The data is now ready for neural network modeling in Notebook 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
